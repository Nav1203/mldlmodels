{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "from keras.datasets.mnist import load_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "(train_data,train_labels),(test_data,test_labels)=load_data()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "train_data.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "test_data.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "# Train Data \r\n",
    "train_data[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "img=train_data[1000]\r\n",
    "plt.imshow(img,cmap='gray')\r\n",
    "plt.title(\"Label: %i\"%train_labels[1000])\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQJklEQVR4nO3df4wc9X3G8ffD5UJa21FtXIM5IA7GINIKSG25kWylFJrERUQQYSAWEY4wdf6IRVMCFCgI2hRhR00wVVGki/hhu4n5ERywKEqCEJSUCsrZwtjgJhjLgMPhwzYJhhqBzad/7Fx0Njuzx+yPWd/3eUmr3Z3PzszHKz83Mzuz+1VEYGZj32FVN2BmneGwmyXCYTdLhMNulgiH3SwRDrtZIhz2hEl6XNKlnZ7XquGwjwGStkn6q6r7KCLp7yS9Lul3ku6QdHjVPaXGYbe2k/Ql4GrgTGAacDzwj1X2lCKHfQyTNFHSQ5LekPRm9viYg142XdL/ZFvcByVNGjH/5yT9t6TfStog6fSSrSwEbo+I5yPiTeA7wNdLLstKctjHtsOAO4FPAccBe4F/O+g1FwOXAEcD+4B/BZDUB/wH8M/AJOAK4H5Jf3zwSiQdl/1BOC6njz8BNox4vgE4UtIRJf9dVoLDPoZFxK6IuD8i/i8i9gA3AX9x0MtWRcSmiHgHuB64QFIP8DXg4Yh4OCI+iIhHgAHgrDrreSUi/igiXslpZTzwuxHPhx9PaOKfZx/Rx6puwNpH0h8CtwDzgInZ5AmSeiJif/b81RGzvAz0ApOp7Q2cL+nLI+q9wGMlWnkb+OSI58OP95RYlpXkLfvY9m3gJODPI+KTwOez6RrxmmNHPD4OeB/YSe2PwKpsiz18GxcRS0v08Txw6ojnpwI7ImJXiWVZSQ772NEr6RMjbh+jtpu8F/ht9sHbDXXm+5qkz2R7Af8E/CTb6v878GVJX5LUky3z9Dof8I3GSmBRtp6JwHXAXWX+kVaewz52PEwt2MO3G4HlwB9Q21I/BfysznyrqAXvdeATwGUAEfEqcA5wLfAGtS39ldT5P5N9QPd23gd0EfEz4LvUDgFezm71/vBYG8k/XmGWBm/ZzRLhsJslwmE3S4TDbpaIjl5UI8mfBpq1WUSo3vSmtuyS5kn6laQtkq5uZllm1l6lT71l10//GvgCsB14BlgQES8UzOMtu1mbtWPLPhvYEhFbI+I94G5qF2GYWRdqJux9HPgliu3ZtANIWixpQNJAE+sysyY18wFdvV2FD+2mR0Q/0A/ejTerUjNb9u0c+I2pY4DXmmvHzNqlmbA/A8yQ9GlJHwe+CqxtTVtm1mqld+MjYp+kJcDPgR7gjoh4vmWdmVlLdfRbbz5mN2u/tlxUY2aHDofdLBEOu1kiHHazRDjsZolw2M0S4bCbJcJhN0uEw26WCIfdLBEOu1kiHHazRDjsZolw2M0S4bCbJcJhN0uEw26WCIfdLBEOu1kiHHazRDjsZolw2M0S4bCbJcJhN0uEw26WCIfdLBEOu1kiHHazRDjsZokoPWSzpeGEE04orF922WWF9SVLluTWpLqDjf7evn37CuuXXnppYX316tW5tffee69w3rGoqbBL2gbsAfYD+yJiViuaMrPWa8WW/S8jYmcLlmNmbeRjdrNENBv2AH4haZ2kxfVeIGmxpAFJA02uy8ya0Oxu/JyIeE3SFOARSf8bEU+MfEFE9AP9AJKiyfWZWUlNbdkj4rXsfgj4KTC7FU2ZWeuVDrukcZImDD8GvghsalVjZtZaiii3Zy3peGpbc6gdDvw4Im5qMI934zusp6ensH7xxRcX1pctW1ZYnzx58kfuadjQ0FBhfcqUKaWXDTBjxozc2ksvvdTUsrtZRNS9gKH0MXtEbAVOLd2RmXWUT72ZJcJhN0uEw26WCIfdLBEOu1kiSp96K7Uyn3priwULFuTWZs6cWTjv5Zdf3tS6H3jggcL6bbfdlltrdPrr7rvvLqzPnl18Ddfjjz+eWzvjjDMK5z2U5Z1685bdLBEOu1kiHHazRDjsZolw2M0S4bCbJcJhN0uEz7MfAop+jhng1ltvza01+rnmXbt2FdbnzZtXWF+/fn1hvZn/X+PHjy+sv/XWW6XXPWfOnMJ5n3rqqcJ6N/N5drPEOexmiXDYzRLhsJslwmE3S4TDbpYIh90sER6yuQs0Op/c6Dx70bn0d955p3Des88+u7C+bt26wno7NRpWefPmzYX1k08+uZXtHPK8ZTdLhMNulgiH3SwRDrtZIhx2s0Q47GaJcNjNEuHz7F1gwoQJhfUTTzyx9LKXL19eWH/66adLL7vdGp1n37hxY2Hd59kP1HDLLukOSUOSNo2YNknSI5JezO4ntrdNM2vWaHbj7wIO/rmSq4FHI2IG8Gj23My6WMOwR8QTwO6DJp8DrMgerwDObW1bZtZqZY/Zj4yIQYCIGJQ0Je+FkhYDi0uux8xapO0f0EVEP9AP/sFJsyqVPfW2Q9JUgOx+qHUtmVk7lA37WmBh9ngh8GBr2jGzdmm4Gy9pNXA6MFnSduAGYClwr6RFwCvA+e1scqw74ogjmpq/6Dvrd955Z1PLtrGjYdgjYkFO6cwW92JmbeTLZc0S4bCbJcJhN0uEw26WCIfdLBH+imsXmD9/flPz33vvvbm1rVu3NrVsGzu8ZTdLhMNulgiH3SwRDrtZIhx2s0Q47GaJcNjNEuHz7B3Q6CusixYtamr5AwMDTc3frQ4//PDC+pw5czrUydjgLbtZIhx2s0Q47GaJcNjNEuGwmyXCYTdLhMNulgifZ++Ak046qbDe19fX1PJ37z54KL6xoaenp7De6H179913c2t79+4t1dOhzFt2s0Q47GaJcNjNEuGwmyXCYTdLhMNulgiH3SwRPs8+Bqxdu7bqFrrSli1bcmsbNmzoYCfdoeGWXdIdkoYkbRox7UZJv5H0bHY7q71tmlmzRrMbfxcwr870WyLitOz2cGvbMrNWaxj2iHgCGJvXY5olpJkP6JZIei7bzZ+Y9yJJiyUNSBqbP5RmdogoG/YfANOB04BB4Ht5L4yI/oiYFRGzSq7LzFqgVNgjYkdE7I+ID4AfArNb25aZtVqpsEuaOuLpV4BNea81s+7Q8Dy7pNXA6cBkSduBG4DTJZ0GBLAN+Eb7WrRULVy4sKn5ly1b1qJOxoaGYY+IBXUm396GXsysjXy5rFkiHHazRDjsZolw2M0S4bCbJUIR0bmVSZ1bWRfp7e0trL/wwguF9enTpxfWx40bl1vr5p9MPuqoowrr69evb2r+o48+Orf2+uuvF857KIsI1ZvuLbtZIhx2s0Q47GaJcNjNEuGwmyXCYTdLhMNulgj/lHQHvP/++4X1/fv3d6iT7jJ37tzCeqPz6I3et05eQ3Io8JbdLBEOu1kiHHazRDjsZolw2M0S4bCbJcJhN0uEz7OPAX19fbm1omGLO2HKlCm5teuuu65w3kbn0RctWlRY37FjR2E9Nd6ymyXCYTdLhMNulgiH3SwRDrtZIhx2s0Q47GaJGM2QzccCK4GjgA+A/oi4VdIk4B5gGrVhmy+IiDfb1+rYdc899xTWr7/++sL6/Pnzc2tLly4t1dNo9fT0FNavuuqq3Nopp5xSOO/g4GBhfeXKlYV1O9Botuz7gG9HxMnA54BvSvoMcDXwaETMAB7NnptZl2oY9ogYjIj12eM9wGagDzgHWJG9bAVwbpt6NLMW+EjH7JKmAZ8FngaOjIhBqP1BAPKvizSzyo362nhJ44H7gW9FxFtS3eGk6s23GFhcrj0za5VRbdkl9VIL+o8iYk02eYekqVl9KjBUb96I6I+IWRExqxUNm1k5DcOu2ib8dmBzRHx/RGktsDB7vBB4sPXtmVmrNByyWdJc4JfARmqn3gCupXbcfi9wHPAKcH5E7G6wLP+2bx3nnXdeYf2+++4rrG/bti23NnPmzMJ533yzubOlF110UWF91apVubXduwv/uzBv3rzC+sDAQGE9VXlDNjc8Zo+I/wLyDtDPbKYpM+scX0FnlgiH3SwRDrtZIhx2s0Q47GaJcNjNEuGfku4Cjz32WGF9165dhfVp06bl1q688srCeW+55ZbC+iWXXFJYL/oKayPLly8vrPs8emt5y26WCIfdLBEOu1kiHHazRDjsZolw2M0S4bCbJaLh99lbujJ/n72UWbOKf+TnySefzK319vYWzrtz587C+qRJkwrrhx1WvL1Ys2ZNbu3CCy8snLfRkM1WX9732b1lN0uEw26WCIfdLBEOu1kiHHazRDjsZolw2M0S4fPsY8AVV1yRW7vmmmsK5504cWJT67755psL60Xfl290jt/K8Xl2s8Q57GaJcNjNEuGwmyXCYTdLhMNulgiH3SwRoxmf/VhgJXAUtfHZ+yPiVkk3An8DvJG99NqIeLjBsnye3azN8s6zjybsU4GpEbFe0gRgHXAucAHwdkT8y2ibcNjN2i8v7A1HhImIQWAwe7xH0magr7XtmVm7faRjdknTgM8CT2eTlkh6TtIdkupedylpsaQBSR7Lx6xCo742XtJ44D+BmyJijaQjgZ1AAN+htqtfODCYd+PN2q/0MTuApF7gIeDnEfH9OvVpwEMR8acNluOwm7VZ6S/CSBJwO7B5ZNCzD+6GfQXY1GyTZtY+o/k0fi7wS2AjtVNvANcCC4DTqO3GbwO+kX2YV7Qsb9nN2qyp3fhWcdjN2s/fZzdLnMNulgiH3SwRDrtZIhx2s0Q47GaJcNjNEuGwmyXCYTdLhMNulgiH3SwRDrtZIhx2s0Q47GaJaPiDky22E3h5xPPJ2bRu1K29dWtf4N7KamVvn8ordPT77B9auTQQEbMqa6BAt/bWrX2BeyurU715N94sEQ67WSKqDnt/xesv0q29dWtf4N7K6khvlR6zm1nnVL1lN7MOcdjNElFJ2CXNk/QrSVskXV1FD3kkbZO0UdKzVY9Pl42hNyRp04hpkyQ9IunF7L7uGHsV9XajpN9k792zks6qqLdjJT0mabOk5yX9bTa90veuoK+OvG8dP2aX1AP8GvgCsB14BlgQES90tJEckrYBsyKi8gswJH0eeBtYOTy0lqTvArsjYmn2h3JiRPx9l/R2Ix9xGO829ZY3zPjXqfC9a+Xw52VUsWWfDWyJiK0R8R5wN3BOBX10vYh4Ath90ORzgBXZ4xXU/rN0XE5vXSEiBiNiffZ4DzA8zHil711BXx1RRdj7gFdHPN9Od433HsAvJK2TtLjqZuo4cniYrex+SsX9HKzhMN6ddNAw413z3pUZ/rxZVYS93tA03XT+b05E/Bnw18A3s91VG50fANOpjQE4CHyvymayYcbvB74VEW9V2ctIdfrqyPtWRdi3A8eOeH4M8FoFfdQVEa9l90PAT6kddnSTHcMj6Gb3QxX383sRsSMi9kfEB8APqfC9y4YZvx/4UUSsySZX/t7V66tT71sVYX8GmCHp05I+DnwVWFtBHx8iaVz2wQmSxgFfpPuGol4LLMweLwQerLCXA3TLMN55w4xT8XtX+fDnEdHxG3AWtU/kXwL+oYoecvo6HtiQ3Z6vujdgNbXduvep7REtAo4AHgVezO4ndVFvq6gN7f0ctWBNrai3udQODZ8Dns1uZ1X93hX01ZH3zZfLmiXCV9CZJcJhN0uEw26WCIfdLBEOu1kiHHazRDjsZon4f/WdBbE0IgggAAAAAElFTkSuQmCC"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Image Shape Transformation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "# For greyscale image shape must be changed to 28 x 28 x 1\r\n",
    "image_height=28\r\n",
    "image_width=28\r\n",
    "\r\n",
    "# Gray Scale Image with number of channels = 1 (Rank)\r\n",
    "num_channels=1\r\n",
    "\r\n",
    "# Reshaping of Image Handwritten MNIST Data\r\n",
    "train_digits=np.reshape(train_data,newshape=(60000,image_height,image_width,num_channels))\r\n",
    "test_digits=np.reshape(test_data,newshape=(10000,image_height,image_width,num_channels))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "train_digits.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Image Pixel Normalization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "# scaling of image data\r\n",
    "train_digits=train_digits.astype('float32')/255\r\n",
    "test_digits=test_digits.astype('float32')/255"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "# There are 10\r\n",
    "train_labels[0:10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "from tensorflow.keras.utils import to_categorical\r\n",
    "num_classes=10\r\n",
    "train_labels_class=to_categorical(train_labels,num_classes)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "train_labels_class"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\r\n",
    "from keras.models import Sequential\r\n",
    "from keras.optimizers import Adam\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "def build_model():\r\n",
    "    model = Sequential()\r\n",
    "\r\n",
    "    # Convolutional Neural Network - I\r\n",
    "    # padding='same' : Zero Padding , padding='valid'\r\n",
    "    model.add(Conv2D(filters = 32, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', \r\n",
    "                     input_shape = (image_height, image_width, num_channels)))\r\n",
    "    # MaxPooling\r\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
    "\r\n",
    "    # Conv2D - II\r\n",
    "    model.add(Conv2D(filters = 64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\r\n",
    "    # MaxPooling\r\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
    "\r\n",
    "    # Conv2D - III\r\n",
    "    model.add(Conv2D(filters = 64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\r\n",
    "    # MaxPooling\r\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
    "\r\n",
    "    # Flatten Layer\r\n",
    "    model.add(Flatten())\r\n",
    "\r\n",
    "    # Fully Connected layer\r\n",
    "    model.add(Dense(units = 128, activation='relu'))\r\n",
    "\r\n",
    "    # Output Layer\r\n",
    "    # Activation function for multiclass classification = SOFTMAX\r\n",
    "    model.add(Dense(units = 10, activation='softmax'))\r\n",
    "\r\n",
    "    optimizers = Adam(learning_rate= 0.0001)\r\n",
    "\r\n",
    "    model.compile(optimizer = optimizers, loss = 'categorical_crossentropy', metrics = ['accuracy'])\r\n",
    "\r\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "model=build_model()\r\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               73856     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 130,890\n",
      "Trainable params: 130,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "from keras import callbacks\r\n",
    "filepath=\"E:\\Ai\\Best_MNIST.hdf5\"\r\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath, monitor = 'val_loss', save_best_model = True, mode = 'min', verbose = 1)\r\n",
    "checkpoint"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.ModelCheckpoint at 0x2330348edf0>"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "import datetime\r\n",
    "import keras\r\n",
    "import os\r\n",
    "logdir = os.path.join(\"E:\\Ai\\logs_MNIST\", datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))\r\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(logdir)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "history = model.fit(train_digits, train_labels_class, epochs = 15, batch_size= 64, validation_split = 0.1, callbacks = [checkpoint, tensorboard_callback])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/15\n",
      "844/844 [==============================] - 53s 49ms/step - loss: 0.5555 - accuracy: 0.8486 - val_loss: 0.1373 - val_accuracy: 0.9605\n",
      "\n",
      "Epoch 00001: saving model to E:\\Ai\\Best_MNIST.hdf5\n",
      "Epoch 2/15\n",
      "844/844 [==============================] - 35s 42ms/step - loss: 0.1363 - accuracy: 0.9595 - val_loss: 0.0858 - val_accuracy: 0.9765\n",
      "\n",
      "Epoch 00002: saving model to E:\\Ai\\Best_MNIST.hdf5\n",
      "Epoch 3/15\n",
      "844/844 [==============================] - 32s 38ms/step - loss: 0.0964 - accuracy: 0.9700 - val_loss: 0.0705 - val_accuracy: 0.9802\n",
      "\n",
      "Epoch 00003: saving model to E:\\Ai\\Best_MNIST.hdf5\n",
      "Epoch 4/15\n",
      "844/844 [==============================] - 31s 36ms/step - loss: 0.0778 - accuracy: 0.9758 - val_loss: 0.0648 - val_accuracy: 0.9815\n",
      "\n",
      "Epoch 00004: saving model to E:\\Ai\\Best_MNIST.hdf5\n",
      "Epoch 5/15\n",
      "844/844 [==============================] - 30s 36ms/step - loss: 0.0673 - accuracy: 0.9791 - val_loss: 0.0610 - val_accuracy: 0.9827\n",
      "\n",
      "Epoch 00005: saving model to E:\\Ai\\Best_MNIST.hdf5\n",
      "Epoch 6/15\n",
      "844/844 [==============================] - 29s 34ms/step - loss: 0.0584 - accuracy: 0.9815 - val_loss: 0.0561 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00006: saving model to E:\\Ai\\Best_MNIST.hdf5\n",
      "Epoch 7/15\n",
      "844/844 [==============================] - 30s 36ms/step - loss: 0.0515 - accuracy: 0.9840 - val_loss: 0.0492 - val_accuracy: 0.9875\n",
      "\n",
      "Epoch 00007: saving model to E:\\Ai\\Best_MNIST.hdf5\n",
      "Epoch 8/15\n",
      "844/844 [==============================] - 30s 35ms/step - loss: 0.0462 - accuracy: 0.9859 - val_loss: 0.0513 - val_accuracy: 0.9853\n",
      "\n",
      "Epoch 00008: saving model to E:\\Ai\\Best_MNIST.hdf5\n",
      "Epoch 9/15\n",
      "844/844 [==============================] - 31s 36ms/step - loss: 0.0420 - accuracy: 0.9864 - val_loss: 0.0467 - val_accuracy: 0.9873\n",
      "\n",
      "Epoch 00009: saving model to E:\\Ai\\Best_MNIST.hdf5\n",
      "Epoch 10/15\n",
      "844/844 [==============================] - 30s 35ms/step - loss: 0.0384 - accuracy: 0.9876 - val_loss: 0.0429 - val_accuracy: 0.9888\n",
      "\n",
      "Epoch 00010: saving model to E:\\Ai\\Best_MNIST.hdf5\n",
      "Epoch 11/15\n",
      "844/844 [==============================] - 28s 33ms/step - loss: 0.0350 - accuracy: 0.9891 - val_loss: 0.0455 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00011: saving model to E:\\Ai\\Best_MNIST.hdf5\n",
      "Epoch 12/15\n",
      "844/844 [==============================] - 32s 38ms/step - loss: 0.0322 - accuracy: 0.9901 - val_loss: 0.0441 - val_accuracy: 0.9873\n",
      "\n",
      "Epoch 00012: saving model to E:\\Ai\\Best_MNIST.hdf5\n",
      "Epoch 13/15\n",
      "844/844 [==============================] - 36s 42ms/step - loss: 0.0293 - accuracy: 0.9902 - val_loss: 0.0426 - val_accuracy: 0.9888\n",
      "\n",
      "Epoch 00013: saving model to E:\\Ai\\Best_MNIST.hdf5\n",
      "Epoch 14/15\n",
      "844/844 [==============================] - 44s 52ms/step - loss: 0.0263 - accuracy: 0.9916 - val_loss: 0.0469 - val_accuracy: 0.9877\n",
      "\n",
      "Epoch 00014: saving model to E:\\Ai\\Best_MNIST.hdf5\n",
      "Epoch 15/15\n",
      "844/844 [==============================] - 43s 51ms/step - loss: 0.0255 - accuracy: 0.9916 - val_loss: 0.0393 - val_accuracy: 0.9883\n",
      "\n",
      "Epoch 00015: saving model to E:\\Ai\\Best_MNIST.hdf5\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "predictions = model.predict(test_digits) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "# np.argmax converts categorical o/p into integer o/p\r\n",
    "yhat = np.argmax(predictions, axis = 1) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "test_labels_class = to_categorical(test_labels, num_classes)\r\n",
    "model.evaluate(test_digits, test_labels_class)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0309 - accuracy: 0.9894\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.030928265303373337, 0.9894000291824341]"
      ]
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import classification_report\r\n",
    "print(classification_report(test_labels, yhat))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import confusion_matrix\r\n",
    "plt.figure(figsize = (13,8))\r\n",
    "sns.heatmap(confusion_matrix(test_labels, yhat), annot = True, fmt = '0.0f') "
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit (conda)"
  },
  "interpreter": {
   "hash": "8dce89ea0a1dabb18c453c51bd2b3026b7bacca71a7a950d5eeddd788c2a9563"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}